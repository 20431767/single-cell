{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import matplotlib.pyplot as plt\n",
    "# import numpy as np\n",
    "# %matplotlib widget\n",
    "\n",
    "# # Fixing random state for reproducibility\n",
    "# np.random.seed(19680801)\n",
    "\n",
    "# fig, axs = plt.subplots(2, 2)\n",
    "\n",
    "# axs[0, 0].imshow(np.random.random((100, 100)))\n",
    "\n",
    "# axs[0, 1].imshow(np.random.random((100, 100)))\n",
    "\n",
    "# axs[1, 0].imshow(np.random.random((100, 100)))\n",
    "\n",
    "# axs[1, 1].imshow(np.random.random((100, 100)))\n",
    "\n",
    "# plt.subplot_tool()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.metrics.cluster import *\n",
    "from sklearn.metrics import *\n",
    "import scanpy as sc\n",
    "from scipy.optimize import linear_sum_assignment\n",
    "import numpy as np\n",
    "import umap\n",
    "import phate\n",
    "%matplotlib widget"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# for hg in hgs:\n",
    "#     for dim in dims:\n",
    "#         monocle2_cluster_file = \"hg%s.monocle2.cluster.txt\" % hg\n",
    "#         monocle2_anno_file = \"hg%s.monocle2.anno.txt\" % hg\n",
    "#         for dataset_dir in dataset_dirs:\n",
    "#             ref_anno = np.loadtxt(os.path.join(data_dir, dataset_dir, \"0.1.Y.csv\"), dtype=int)\n",
    "#             cluster = np.genfromtxt(os.path.join(data_dir, dataset_dir, output_dir, monocle2_cluster_file), dtype=int)\n",
    "#             anno = np.loadtxt(os.path.join(data_dir, dataset_dir, output_dir, monocle2_anno_file), dtype=int)\n",
    "#             assert anno[anno.shape[0] // 2:].shape == cluster[cluster.shape[0] // 2:].shape\n",
    "#             assert anno[anno.shape[0] // 2:].shape[0] == ref_anno.shape[0] * 10\n",
    "#             np.savetxt(os.path.join(data_dir, dataset_dir, output_dir, monocle2_cluster_file), cluster[cluster.shape[0] // 2:], fmt=\"%d\")\n",
    "#             np.savetxt(os.path.join(data_dir, dataset_dir, output_dir, monocle2_anno_file), cluster[anno.shape[0] // 2:], fmt=\"%d\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recover_labels(y_true, y_pred):\n",
    "    unique_cluster, y_pred = np.unique(y_pred, return_inverse=True)\n",
    "#     print(np.unique(unique_cluster))\n",
    "    # if a method cannot produce results, assign the worst result for it\n",
    "    if len(unique_cluster) == 1:\n",
    "        print(\"This method cannot produce cluster at all.\")\n",
    "        for i in range(len(np.unique(y_true))):\n",
    "            y_pred[i] = i\n",
    "#     print(\"idx: \", np.unique(y_pred))\n",
    "    counting_mat = contingency_matrix(y_true, y_pred)\n",
    "#     # print(counting_mat)\n",
    "#     y_pred_anno_idx = counting_mat.argmax(axis=0)\n",
    "#     # annotate back can only supporting corresponding clustering number\n",
    "#     y_pred_anno_dict = {i: y_pred_anno_idx[i] for i in range(len(y_pred_anno_idx))}\n",
    "#     #y_pred_anno_dict = {i: y_pred_anno_idx[i] for i in np.unique(y_pred)}\n",
    "#     y_pred_anno = np.array([y_pred_anno_dict[k] for k in y_pred])\n",
    "    row_idx, col_idx = linear_sum_assignment(counting_mat.max() - counting_mat)\n",
    "#     print(row_idx, col_idx)\n",
    "    y_pred_anno_dict = {c: r for r, c in zip(row_idx, col_idx)}\n",
    "#     from munkres import Munkres\n",
    "#     m = Munkres()\n",
    "#     indices = m.compute(counting_mat.max() - counting_mat)\n",
    "#     print(\"indices: \",indices)\n",
    "#     Y_pred_anno_dict = {column: row for row,column in indices}\n",
    "    y_pred_anno = np.array([y_pred_anno_dict[k] for k in y_pred])\n",
    "    return y_pred_anno"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluation Function\n",
    "def purity_score(y_true, y_pred):\n",
    "    # compute contingency matrix (also called confusion matrix)\n",
    "    counting_mat = contingency_matrix(y_true, y_pred)\n",
    "    return np.sum(np.amax(counting_mat, axis=0)) / np.sum(counting_mat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def average_silhouette_width(X, Y, batch):\n",
    "    asw_batch = silhouette_score(X, batch)\n",
    "    asw_celltype = silhouette_score(X, Y)\n",
    "    min_val = -1\n",
    "    max_val = 1\n",
    "    asw_batch_norm = (asw_batch - min_val) / (max_val - min_val)\n",
    "    asw_celltype_norm = (asw_celltype - min_val) / (max_val - min_val)\n",
    "    return (2 * (1 - asw_batch_norm)*(asw_celltype_norm))/(1 - asw_batch_norm + asw_celltype_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dataset_dirs = [\"human_pancreas\", \"human_melanoma\", \"mouse_stem\", \"mouse_pancreas\", \"human_progenitor\", \"mouse_cortex\"]\n",
    "dataset_dirs = [\"human_progenitor\", \"human_colorectal_cancer\", \"mouse_cortex\", \"mouse_stem\", \"human_melanoma\", \"human_pancreas\", \"mouse_pancreas\", \"mouse_blastomeres\", \"mouse_pancreatic_circulating_tumor\", \"human_embryos\", \"splatter\", 'mars_skin', \"mars_limb_muscle\", 'mars_tongue', 'mars_bladder', 'mars_liver', 'mars_trachea', 'mars_mammary_gland', 'mars_spleen'] #]\n",
    "dataset_dirs = [\"human_pancreas\", \"mouse_pancreas\", \"human_melanoma\", \"mouse_stem\", \"mouse_cortex\", \"human_progenitor\", 'mars_skin', \"mars_limb_muscle\", 'mars_bladder', 'mars_trachea', 'mars_mammary_gland', 'mars_spleen']\n",
    "# splatter_dataset_dirs = [\"splatter_equal_group_2\", \"splatter_equal_group_3\", \"splatter_equal_group_4\", \"splatter_equal_group_5\", \"splatter_equal_group_6\", \"splatter_equal_group_7\", \"splatter_equal_group_8\", \"splatter_equal_group_9\", \"splatter_equal_group_10\"]\n",
    "# splatter_dataset_dirs = [\"splatter_each_group_2\", \"splatter_each_group_3\", \"splatter_each_group_4\", \"splatter_each_group_5\", \"splatter_each_group_6\", \"splatter_each_group_7\", \"splatter_each_group_8\", \"splatter_each_group_9\", \"splatter_each_group_10\"]\n",
    "# splatter_dataset_dirs = [\"splatter_each_group_10\"]\n",
    "# splatter_dataset_dirs = [\"splatter_dropout_11\", \"splatter_dropout_10\", \"splatter_dropout_9\", \"splatter_dropout_8\", \"splatter_dropout_7\", \"splatter_dropout_6\", \"splatter_dropout_5\", \"splatter_dropout_4\", \"splatter_dropout_3\", \"splatter_dropout_2\"]\n",
    "splatter_dataset_dirs = [\"splatter_dropout_3\"]\n",
    "dataset_dirs = splatter_dataset_dirs\n",
    "\n",
    "dataset_dirs = [\"splatter_batch_2\", \"splatter_batch_3\", \"splatter_batch_4\"] #, \"splatter_batch_5\"]\n",
    "# dataset_dirs = [\"splatter_batch_5\"]\n",
    "dataset_dirs_batch = [\"human_pancreas\", \"mouse_pancreas\", \"human_colorectal_cancer\"]\n",
    "dataset_dirs_batch += [\"splatter_batch_2\", \"splatter_batch_3\", \"splatter_batch_4\", \"splatter_batch_5\"]\n",
    "methods_non_deterministic_cluster_num = [\"seurat\", \"scvi\"]\n",
    "\n",
    "#dataset_dirs = ['mars_skin', 'mars_tongue', 'mars_bladder', 'mars_liver']\n",
    "#dataset_dirs = [\"mars_limb_muscle\", 'mars_trachea', 'mars_mammary_gland']\n",
    "# extreme good performance datasets: [\"mars_limb_muscle\", 'mars_mammary_gland', 'mars_bladder']\n",
    "#--\n",
    "# good performance datasets: [\"mars_trachea\", 'mars_skin']\n",
    "# just-so-so performance datasets: [\"mars_liver\", 'mars_tongue']\n",
    "#--\n",
    "# low performance datasets: ['mars_thymus', \"mouse_blastomeres\", \"human_cell_line\", \"human_colorectal_cancer\", \"mouse_embryos\", \"mouse_pancreatic_circulating_tumor\", \"human_embryos\"]\n",
    "# "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dataset_dirs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dir = \"F:/OneDrive - Hong Kong Baptist University/year1_1/cgi_datasets\"\n",
    "data_dir = \"E:/OneDrive - stu.hit.edu.cn/year1_1/cgi_datasets\"\n",
    "output_dirs = [\"output\"]\n",
    "output_dirs = [\"test-batch\"]\n",
    "output_dirs = [\"test-input_count_X_output_count_X\"]\n",
    "original_output_dir = output_dirs[0]\n",
    "# output_dirs = [\"test-n_init\"]\n",
    "\n",
    "# lambda_bs = [\"0\", \"0.2\", \"0.4\", \"0.6\", \"0.8\", \"1.0\"]\n",
    "# lambda_cs = [\"0\", \"0.2\", \"0.4\", \"0.6\", \"0.8\", \"1.0\"]\n",
    "\n",
    "# output_dirs = []\n",
    "# for lambda_b in lambda_bs:\n",
    "\n",
    "#     for lambda_c in lambda_cs:\n",
    "#         output_dirs.append(\"test-entropy-mask-lambda_b_%s-lambda_c_%s\" %(lambda_b, lambda_c))\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "hgs = [str(0.1)]\n",
    "hgs = list(map(str, [x / 10.0 for x in range(5, 8)]))\n",
    "hgs = list(map(str, [x / 10.0 for x in range(1, 3)]))\n",
    "# dims = [25, 100, 400, 1000]\n",
    "dims = [400]\n",
    "dim = 400\n",
    "repeat_num = 10\n",
    "repeat_num = 1\n",
    "plot_metric = 'ARI'\n",
    "plot_flag = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hg0.1-dim400-inherit-KMeans.cluster.txt\n",
      "hg0.1-dim400-reinit-KMeans.cluster.txt\n",
      "hg0.1-dim400-inherit-KMeans-L2.cluster.txt\n",
      "hg0.1-dim400-reinit-KMeans-L2.cluster.txt\n",
      "hg0.1.raceid3.cluster.txt\n",
      "hg0.1.sc3.cluster.txt\n",
      "hg0.1.monocle2.cluster.txt\n",
      "hg0.1.seurat.cluster.txt\n",
      "hg0.1.simlr.cluster.txt\n",
      "hg0.1.drjcc.cluster.txt\n",
      "hg0.1.scvi.cluster.txt\n",
      "splatter_batch_2 cell#: 4000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "4639cbaf7a934b72afe77e9eb774e24a",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hg0.1-dim400-inherit-KMeans.cluster.txt\n",
      "hg0.1-dim400-reinit-KMeans.cluster.txt\n",
      "hg0.1-dim400-inherit-KMeans-L2.cluster.txt\n",
      "hg0.1-dim400-reinit-KMeans-L2.cluster.txt\n",
      "hg0.1.raceid3.cluster.txt\n",
      "hg0.1.sc3.cluster.txt\n",
      "hg0.1.monocle2.cluster.txt\n",
      "hg0.1.seurat.cluster.txt\n",
      "hg0.1.simlr.cluster.txt\n",
      "hg0.1.drjcc.cluster.txt\n",
      "hg0.1.scvi.cluster.txt\n",
      "splatter_batch_3 cell#: 6000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f5eecfc510ef46b29c9b82a2c29f07fb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hg0.1-dim400-inherit-KMeans.cluster.txt\n",
      "hg0.1-dim400-reinit-KMeans.cluster.txt\n",
      "hg0.1-dim400-inherit-KMeans-L2.cluster.txt\n",
      "hg0.1-dim400-reinit-KMeans-L2.cluster.txt\n",
      "hg0.1.raceid3.cluster.txt\n",
      "hg0.1.sc3.cluster.txt\n",
      "hg0.1.monocle2.cluster.txt\n",
      "hg0.1.seurat.cluster.txt\n",
      "hg0.1.simlr.cluster.txt\n",
      "hg0.1.drjcc.cluster.txt\n",
      "hg0.1.scvi.cluster.txt\n",
      "splatter_batch_4 cell#: 8000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "55922033d5ba4142903c0125b0df2679",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hg0.2-dim400-inherit-KMeans.cluster.txt\n",
      "hg0.2-dim400-reinit-KMeans.cluster.txt\n",
      "hg0.2-dim400-inherit-KMeans-L2.cluster.txt\n",
      "hg0.2-dim400-reinit-KMeans-L2.cluster.txt\n",
      "hg0.2.raceid3.cluster.txt\n",
      "hg0.2.sc3.cluster.txt\n",
      "hg0.2.monocle2.cluster.txt\n",
      "hg0.2.seurat.cluster.txt\n",
      "hg0.2.simlr.cluster.txt\n",
      "hg0.2.drjcc.cluster.txt\n",
      "hg0.2.scvi.cluster.txt\n",
      "splatter_batch_2 cell#: 4000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7400ae36b12d470494c63de66fad5d58",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hg0.2-dim400-inherit-KMeans.cluster.txt\n",
      "hg0.2-dim400-reinit-KMeans.cluster.txt\n",
      "hg0.2-dim400-inherit-KMeans-L2.cluster.txt\n",
      "hg0.2-dim400-reinit-KMeans-L2.cluster.txt\n",
      "hg0.2.raceid3.cluster.txt\n",
      "hg0.2.sc3.cluster.txt\n",
      "hg0.2.monocle2.cluster.txt\n",
      "hg0.2.seurat.cluster.txt\n",
      "hg0.2.simlr.cluster.txt\n",
      "hg0.2.drjcc.cluster.txt\n",
      "hg0.2.scvi.cluster.txt\n",
      "splatter_batch_3 cell#: 6000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "cdffb57677014ff292849a7c4198c4e5",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hg0.2-dim400-inherit-KMeans.cluster.txt\n",
      "hg0.2-dim400-reinit-KMeans.cluster.txt\n",
      "hg0.2-dim400-inherit-KMeans-L2.cluster.txt\n",
      "hg0.2-dim400-reinit-KMeans-L2.cluster.txt\n",
      "hg0.2.raceid3.cluster.txt\n",
      "hg0.2.sc3.cluster.txt\n",
      "hg0.2.monocle2.cluster.txt\n",
      "hg0.2.seurat.cluster.txt\n",
      "hg0.2.simlr.cluster.txt\n",
      "hg0.2.drjcc.cluster.txt\n",
      "hg0.2.scvi.cluster.txt\n",
      "splatter_batch_4 cell#: 8000\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "7bbfab5b4f954b48aa6f7257a45c4c82",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Canvas(toolbar=Toolbar(toolitems=[('Home', 'Reset original view', 'home', 'home'), ('Back', 'Back to previous …"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finish!\n"
     ]
    }
   ],
   "source": [
    "for output_dir in output_dirs:\n",
    "    for hg in hgs:\n",
    "        for dim in dims:\n",
    "            # all methods\n",
    "            group_names = [\"%s-%d-inherit\" % (hg, dim), \"%s-%d-reinit\" % (hg, dim), \"%s-%d-inherit-L2\" % (hg, dim), \"%s-%d-reinit-L2\" % (hg, dim), \"RaceID3\", \"SC3\", \"Monocle2\", \"Seurat3\", \"SIMLR\", \"DRjCC\", \"scvi\"]\n",
    "            # our methods\n",
    "#             group_names = [\"%s-%d-inherit\" % (hg, dim), \"%s-%d-reinit\" % (hg, dim), \"%s-%d-inherit-L2\" % (hg, dim), \"%s-%d-reinit-L2\" % (hg, dim)]\n",
    "\n",
    "            inherit_cluster_file = \"hg%s-dim%d-inherit-KMeans.cluster.txt\" % (hg, dim)\n",
    "    #         inherit_anno_file = \"hg%s-dim%d-inherit-KMeans.anno.txt\" % (hg, dim)\n",
    "            inherit_l2_cluster_file = \"hg%s-dim%d-inherit-KMeans-L2.cluster.txt\" % (hg, dim)\n",
    "    #         inherit_l2_anno_file = \"hg%s-dim%d-inherit-KMeans-L2.anno.txt\" % (hg, dim)\n",
    "            reinit_cluster_file = \"hg%s-dim%d-reinit-KMeans.cluster.txt\" % (hg, dim)\n",
    "    #         reinit_anno_file = \"hg%s-dim%d-reinit-KMeans.anno.txt\" % (hg, dim)\n",
    "            reinit_l2_cluster_file = \"hg%s-dim%d-reinit-KMeans-L2.cluster.txt\" % (hg, dim)\n",
    "    #         reinit_l2_anno_file = \"hg%s-dim%d-reinit-KMeans-L2.anno.txt\" % (hg, dim)\n",
    "            raceid3_cluster_file = \"hg%s.raceid3.cluster.txt\" % hg\n",
    "    #         raceid3_anno_file = \"hg%s.raceid3.anno.txt\" % hg\n",
    "            sc3_cluster_file = \"hg%s.sc3.cluster.txt\" % hg\n",
    "    #         sc3_anno_file = \"hg%s.sc3.anno.txt\" % hg\n",
    "            monocle2_cluster_file = \"hg%s.monocle2.cluster.txt\" % hg\n",
    "    #         monocle2_anno_file = \"hg%s.monocle2.anno.txt\" % hg\n",
    "            seurat3_cluster_file = \"hg%s.seurat.cluster.txt\" % hg\n",
    "    #         seurat3_anno_file = \"hg%s.seurat.anno.txt\" % hg\n",
    "            simlr_cluster_file = \"hg%s.simlr.cluster.txt\" % hg\n",
    "    #         simlr_anno_file = \"hg%s.simlr.anno.txt\" % hg\n",
    "            drjcc_cluster_file = \"hg%s.drjcc.cluster.txt\" % hg\n",
    "#             drjcc_anno_file = \"hg%s.drjcc.anno.txt\" % hg\n",
    "            scvi_cluster_file = \"hg%s.scvi.cluster.txt\" % hg\n",
    "#             scvi_anno_file = \"hg%s.scvi.anno.txt\" % hg            \n",
    "            X_file = \"%s.X.count.name.csv\" % hg\n",
    "            X_unscaled_file = \"%s.X.name.csv\" % hg\n",
    "            anno_file = \"%s.Y.csv\" % hg\n",
    "            # all methods\n",
    "            cluster_files = [inherit_cluster_file, reinit_cluster_file, inherit_l2_cluster_file, reinit_l2_cluster_file, raceid3_cluster_file, sc3_cluster_file, monocle2_cluster_file, seurat3_cluster_file, simlr_cluster_file, drjcc_cluster_file, scvi_cluster_file]\n",
    "            # our methods\n",
    "#             cluster_files = [inherit_cluster_file, reinit_cluster_file, inherit_l2_cluster_file, reinit_l2_cluster_file]\n",
    "\n",
    "            batch_file = \"%s.batch.csv\" % hg\n",
    "    #         anno_files = [inherit_anno_file, reinit_anno_file, inherit_l2_anno_file, reinit_l2_anno_file, raceid3_anno_file, sc3_anno_file, monocle2_anno_file, seurat3_anno_file, simlr_anno_file]\n",
    "    #         anno_files = [anno_file] * len(cluster_files)\n",
    "    #         X_files = [X_file] * len(cluster_files)\n",
    "            for dataset_dir in dataset_dirs:\n",
    "                df = pd.DataFrame({'method': [g for g in group_names for i in range(repeat_num)]})\n",
    "                anno = np.loadtxt(os.path.join(data_dir, dataset_dir, anno_file), dtype=int)\n",
    "                X = pd.read_csv(os.path.join(data_dir, dataset_dir, X_file), index_col=0)\n",
    "                X_unscaled = pd.read_csv(os.path.join(data_dir, dataset_dir, X_unscaled_file), index_col=0)\n",
    "                adata = sc.AnnData(X_unscaled)\n",
    "                sc.pp.scale(adata)\n",
    "                adata = adata.copy()\n",
    "                X_normalized = adata.X\n",
    "                if dataset_dir in dataset_dirs_batch:\n",
    "                    sc_batch_labels = np.loadtxt(os.path.join(data_dir, dataset_dir, batch_file), dtype=int)\n",
    "                AMI = []\n",
    "                ARI = []\n",
    "    #             CPS = []\n",
    "                FMI = []\n",
    "                NMI = []\n",
    "                JACCARD = []\n",
    "    #             PURITY = []\n",
    "                ASW = []\n",
    "                ACC = []\n",
    "                plot_metric_df = pd.DataFrame()\n",
    "                plot_metric_df['gt'] = anno\n",
    "                plot_metric_df['gt_unscaled'] = anno\n",
    "                plot_metric_df['gt_normalized'] = anno\n",
    "\n",
    "                for cluster_file, group_name in zip(cluster_files, group_names):\n",
    "                    output_dir = original_output_dir\n",
    "                    if group_name.endswith(\"inherit\"):\n",
    "                        plot_metric_df['gt_imX_unscaled_inherit'] = anno\n",
    "                    elif group_name.endswith(\"reinit\"):\n",
    "                        plot_metric_df['gt_imX_unscaled_reinit'] = anno\n",
    "                    elif group_name.endswith(\"inherit-L2\"):\n",
    "                        plot_metric_df['gt_imX_unscaled_inherit_L2'] = anno\n",
    "                    elif group_name.endswith(\"reinit-L2\"):\n",
    "                        plot_metric_df['gt_imX_unscaled_reinit_L2'] = anno\n",
    "                    # !!!\n",
    "                    else:\n",
    "                        output_dir = \"test-batch\"\n",
    "                    print(cluster_file)\n",
    "                    cluster = np.genfromtxt(os.path.join(data_dir, dataset_dir, output_dir, cluster_file), dtype=int, filling_values=1)\n",
    "                    for rep in range(repeat_num):\n",
    "                        one_cluster = cluster[len(cluster)//repeat_num * rep:len(cluster)//repeat_num * (rep + 1)]\n",
    "    #                     one_anno = anno[len(anno)//repeat_num * rep:len(anno)//repeat_num * (rep + 1)]\n",
    "                        one_anno = anno\n",
    "                        one_X = X\n",
    "                        AMI.append(adjusted_mutual_info_score(one_anno, one_cluster))\n",
    "                        ARI.append(adjusted_rand_score(one_anno, one_cluster))\n",
    "    #                     CPS.append(completeness_score(one_anno, one_cluster))\n",
    "                        FMI.append(fowlkes_mallows_score(one_anno, one_cluster))\n",
    "                        NMI.append(normalized_mutual_info_score(one_anno, one_cluster))\n",
    "    #                     PURITY.append(purity_score(one_anno, one_cluster))\n",
    "                        # calculate classification metrics for fixed cluster methods only\n",
    "                        if cluster_file.split('.')[-3] not in methods_non_deterministic_cluster_num:\n",
    "#                             JACCARD.append(jaccard_score(one_anno, recover_labels(one_anno, one_cluster), average='micro'))\n",
    "                            ACC.append(accuracy_score(one_anno, recover_labels(one_anno, one_cluster)))\n",
    "                        else:\n",
    "#                             JACCARD.append(0)\n",
    "                            ACC.append(0)\n",
    "                        # calculate batch metrics for batch datasets only\n",
    "                        if dataset_dir in dataset_dirs_batch:\n",
    "                            one_batch = sc_batch_labels\n",
    "                            if len(np.unique(one_cluster)) != 1:\n",
    "                                ASW.append(average_silhouette_width(one_X, one_cluster, one_batch))\n",
    "                            else:\n",
    "                                ASW.append(0)\n",
    "                        else:\n",
    "                            ASW.append(0)\n",
    "                        # generate 2-D plot according to current best metric\n",
    "                        # lhs: max metric(e.g ARI) value for the current method, rhs: current metric value\n",
    "                        if max(np.array(eval(plot_metric))[df.loc[(df.loc[:, 'method'] == group_name) & ([True] * len(eval(plot_metric)) + [False] * (len(df.index) - len(eval(plot_metric)))), :].index.tolist()]) == \\\n",
    "                            adjusted_rand_score(one_anno, one_cluster) and \\\n",
    "                            cluster_file.split('.')[-3] not in methods_non_deterministic_cluster_num:\n",
    "                            if group_name.endswith(\"inherit\"):\n",
    "                                plot_metric_df['ngt_imX_unscaled_inherit'] = recover_labels(one_anno, one_cluster)\n",
    "                            elif group_name.endswith(\"reinit\"):\n",
    "                                plot_metric_df['ngt_imX_unscaled_reinit'] = recover_labels(one_anno, one_cluster)\n",
    "                            elif group_name.endswith(\"inherit-L2\"):\n",
    "                                plot_metric_df['ngt_imX_unscaled_inherit_L2'] = recover_labels(one_anno, one_cluster)\n",
    "                            elif group_name.endswith(\"reinit-L2\"):\n",
    "                                plot_metric_df['ngt_imX_unscaled_reinit_L2'] = recover_labels(one_anno, one_cluster)\n",
    "                            plot_metric_df[group_name] = recover_labels(one_anno, one_cluster)\n",
    "                print(dataset_dir, \"cell#:\", len(cluster)//repeat_num)\n",
    "                df[\"AMI\"] = AMI\n",
    "                df[\"ARI\"] = ARI\n",
    "    #             df[\"CPS\"] = CPS\n",
    "                df[\"FMI\"] = FMI\n",
    "                df[\"NMI\"] = NMI\n",
    "#                 df[\"JACCARD\"] = JACCARD\n",
    "    #             df[\"PURITY\"] = PURITY\n",
    "                df[\"ASW\"] = ASW\n",
    "                df[\"ACC\"] = ACC\n",
    "                output_dir = original_output_dir\n",
    "#                 df.to_csv(os.path.join(data_dir, dataset_dir, output_dir, \"hg%s-dim%d-all.csv\" %(hg, dim)))\n",
    "                # plot\n",
    "                if plot_flag is True:\n",
    "                    plot_kinds = ['PCA', 't-SNE', 'UMAP', 'PHATE']\n",
    "                    pca = PCA(n_components=2)\n",
    "                    X_r = pca.fit_transform(X)\n",
    "                    X_embedded = TSNE().fit_transform(X)\n",
    "                    reducer = umap.UMAP()\n",
    "                    embedding = reducer.fit_transform(X)\n",
    "                    phate_op = phate.PHATE(verbose=False)\n",
    "                    data_phate = phate_op.fit_transform(X)\n",
    "                    \n",
    "                    pca_X_unscaled = PCA(n_components=2)\n",
    "                    X_r_X_unscaled = pca.fit_transform(X_unscaled)\n",
    "                    X_embedded_X_unscaled = TSNE().fit_transform(X_unscaled)\n",
    "                    reducer_X_unscaled = umap.UMAP()\n",
    "                    embedding_X_unscaled = reducer_X_unscaled.fit_transform(X_unscaled)\n",
    "                    phate_op_X_unscaled = phate.PHATE(verbose=False)\n",
    "                    data_phate_X_unscaled = phate_op_X_unscaled.fit_transform(X_unscaled)\n",
    "\n",
    "                    pca_X_normalized = PCA(n_components=2)\n",
    "                    X_r_X_normalized = pca.fit_transform(X_normalized)\n",
    "                    X_embedded_X_normalized = TSNE().fit_transform(X_normalized)\n",
    "                    reducer_X_normalized = umap.UMAP()\n",
    "                    embedding_X_normalized = reducer_X_normalized.fit_transform(X_normalized)\n",
    "                    phate_op_X_normalized = phate.PHATE(verbose=False)\n",
    "                    data_phate_X_normalized = phate_op_X_normalized.fit_transform(X_normalized)\n",
    "                    \n",
    "                    imX_inherit = pd.read_csv(os.path.join(data_dir, dataset_dir, output_dir, \"hg%s-dim%d-inherit-KMeans.1.imx.txt\" %(hg, dim)), index_col=0)\n",
    "\n",
    "                    pca_imX_inherit = PCA(n_components=2)\n",
    "                    X_r_imX_inherit = pca.fit_transform(imX_inherit)\n",
    "                    X_embedded_imX_inherit = TSNE().fit_transform(imX_inherit)\n",
    "                    reducer_imX_inherit = umap.UMAP()\n",
    "                    embedding_imX_inherit = reducer_imX_inherit.fit_transform(imX_inherit)\n",
    "                    phate_op_imX_inherit = phate.PHATE(verbose=False)\n",
    "                    data_phate_imX_inherit = phate_op_imX_inherit.fit_transform(imX_inherit)\n",
    "                    \n",
    "                    imX_reinit = pd.read_csv(os.path.join(data_dir, dataset_dir, output_dir, \"hg%s-dim%d-reinit-KMeans.1.imx.txt\" %(hg, dim)), index_col=0)\n",
    "\n",
    "                    pca_imX_reinit = PCA(n_components=2)\n",
    "                    X_r_imX_reinit = pca.fit_transform(imX_reinit)\n",
    "                    X_embedded_imX_reinit = TSNE().fit_transform(imX_reinit)\n",
    "                    reducer_imX_reinit = umap.UMAP()\n",
    "                    embedding_imX_reinit = reducer_imX_reinit.fit_transform(imX_reinit)\n",
    "                    phate_op_imX_reinit = phate.PHATE(verbose=False)\n",
    "                    data_phate_imX_reinit = phate_op_imX_reinit.fit_transform(imX_reinit)\n",
    "                    \n",
    "                    imX_inherit_L2 = pd.read_csv(os.path.join(data_dir, dataset_dir, output_dir, \"hg%s-dim%d-inherit-KMeans-L2.1.imx.txt\" %(hg, dim)), index_col=0)\n",
    "\n",
    "                    pca_imX_inherit_L2 = PCA(n_components=2)\n",
    "                    X_r_imX_inherit_L2 = pca.fit_transform(imX_inherit_L2)\n",
    "                    X_embedded_imX_inherit_L2 = TSNE().fit_transform(imX_inherit_L2)\n",
    "                    reducer_imX_inherit_L2 = umap.UMAP()\n",
    "                    embedding_imX_inherit_L2 = reducer_imX_inherit_L2.fit_transform(imX_inherit_L2)\n",
    "                    phate_op_imX_inherit_L2 = phate.PHATE(verbose=False)\n",
    "                    data_phate_imX_inherit_L2 = phate_op_imX_inherit_L2.fit_transform(imX_inherit_L2)\n",
    "                    \n",
    "                    imX_reinit_L2 = pd.read_csv(os.path.join(data_dir, dataset_dir, output_dir, \"hg%s-dim%d-reinit-KMeans-L2.1.imx.txt\" %(hg, dim)), index_col=0)\n",
    "\n",
    "                    pca_imX_reinit_L2 = PCA(n_components=2)\n",
    "                    X_r_imX_reinit_L2 = pca.fit_transform(imX_reinit_L2)\n",
    "                    X_embedded_imX_reinit_L2 = TSNE().fit_transform(imX_reinit_L2)\n",
    "                    reducer_imX_reinit_L2 = umap.UMAP()\n",
    "                    embedding_imX_reinit_L2 = reducer_imX_reinit_L2.fit_transform(imX_reinit_L2)\n",
    "                    phate_op_imX_reinit_L2 = phate.PHATE(verbose=False)\n",
    "                    data_phate_imX_reinit_L2 = phate_op_imX_reinit_L2.fit_transform(imX_reinit_L2)\n",
    "                    \n",
    "                    fig, axes = plt.subplots(len(plot_kinds), len(plot_metric_df.columns), figsize=(12, 8))\n",
    "                    scatter_marker_size = 0.1 # None\n",
    "                    linewidths = None #0 # None\n",
    "\n",
    "                    #axes = axes.flatten()\n",
    "                    # j for columns, i for rows\n",
    "                    for j in range(len(plot_metric_df.columns)):\n",
    "                        if j in [0, 5, 8, 11, 14]: # raw X embedding\n",
    "                            axes[0, j].scatter(X_r[:, 0], X_r[:, 1], c=plot_metric_df.iloc[:, j], s=scatter_marker_size, linewidths=linewidths)\n",
    "                            axes[1, j].scatter(X_embedded[:, 0], X_embedded[:, 1], c=plot_metric_df.iloc[:, j], s=scatter_marker_size, linewidths=linewidths)\n",
    "                            axes[2, j].scatter(embedding[:, 0], embedding[:, 1], c=plot_metric_df.iloc[:, j], s=scatter_marker_size, linewidths=linewidths)\n",
    "                            axes[3, j].scatter(data_phate[:, 0], data_phate[:, 1], c=plot_metric_df.iloc[:, j], s=scatter_marker_size, linewidths=linewidths)\n",
    "                        elif j in [1]: # X_unscaled \n",
    "                            axes[0, j].scatter(X_r_X_unscaled[:, 0], X_r_X_unscaled[:, 1], c=plot_metric_df.iloc[:, j], s=scatter_marker_size, linewidths=linewidths)\n",
    "                            axes[1, j].scatter(X_embedded_X_unscaled[:, 0], X_embedded_X_unscaled[:, 1], c=plot_metric_df.iloc[:, j], s=scatter_marker_size, linewidths=linewidths)\n",
    "                            axes[2, j].scatter(embedding_X_unscaled[:, 0], embedding_X_unscaled[:, 1], c=plot_metric_df.iloc[:, j], s=scatter_marker_size, linewidths=linewidths)\n",
    "                            axes[3, j].scatter(data_phate_X_unscaled[:, 0], data_phate_X_unscaled[:, 1], c=plot_metric_df.iloc[:, j], s=scatter_marker_size, linewidths=linewidths)\n",
    "                        elif j in [2]: # X_normalized\n",
    "                            axes[0, j].scatter(X_r_X_normalized[:, 0], X_r_X_normalized[:, 1], c=plot_metric_df.iloc[:, j], s=scatter_marker_size, linewidths=linewidths)\n",
    "                            axes[1, j].scatter(X_embedded_X_normalized[:, 0], X_embedded_X_normalized[:, 1], c=plot_metric_df.iloc[:, j], s=scatter_marker_size, linewidths=linewidths)\n",
    "                            axes[2, j].scatter(embedding_X_normalized[:, 0], embedding_X_normalized[:, 1], c=plot_metric_df.iloc[:, j], s=scatter_marker_size, linewidths=linewidths)\n",
    "                            axes[3, j].scatter(data_phate_X_normalized[:, 0], data_phate_X_normalized[:, 1], c=plot_metric_df.iloc[:, j], s=scatter_marker_size, linewidths=linewidths)\n",
    "                        elif j in [3, 4]: # gt_imX_inherit ngt_imX_inherit\n",
    "                            axes[0, j].scatter(X_r_imX_inherit[:, 0], X_r_imX_inherit[:, 1], c=plot_metric_df.iloc[:, j], s=scatter_marker_size, linewidths=linewidths)\n",
    "                            axes[1, j].scatter(X_embedded_imX_inherit[:, 0], X_embedded_imX_inherit[:, 1], c=plot_metric_df.iloc[:, j], s=scatter_marker_size, linewidths=linewidths)\n",
    "                            axes[2, j].scatter(embedding_imX_inherit[:, 0], embedding_imX_inherit[:, 1], c=plot_metric_df.iloc[:, j], s=scatter_marker_size, linewidths=linewidths)\n",
    "                            axes[3, j].scatter(data_phate_imX_inherit[:, 0], data_phate_imX_inherit[:, 1], c=plot_metric_df.iloc[:, j], s=scatter_marker_size, linewidths=linewidths)\n",
    "                        elif j in [6, 7]: # gt_imX_reinit ngt_imX_reinit\n",
    "                            axes[0, j].scatter(X_r_imX_reinit[:, 0], X_r_imX_reinit[:, 1], c=plot_metric_df.iloc[:, j], s=scatter_marker_size, linewidths=linewidths)\n",
    "                            axes[1, j].scatter(X_embedded_imX_reinit[:, 0], X_embedded_imX_reinit[:, 1], c=plot_metric_df.iloc[:, j], s=scatter_marker_size, linewidths=linewidths)\n",
    "                            axes[2, j].scatter(embedding_imX_reinit[:, 0], embedding_imX_reinit[:, 1], c=plot_metric_df.iloc[:, j], s=scatter_marker_size, linewidths=linewidths)\n",
    "                            axes[3, j].scatter(data_phate_imX_reinit[:, 0], data_phate_imX_reinit[:, 1], c=plot_metric_df.iloc[:, j], s=scatter_marker_size, linewidths=linewidths)\n",
    "                        elif j in [9, 10]: # gt_imX_inherit_L2 ngt_imX_inherit_L2\n",
    "                            axes[0, j].scatter(X_r_imX_inherit_L2[:, 0], X_r_imX_inherit_L2[:, 1], c=plot_metric_df.iloc[:, j], s=scatter_marker_size, linewidths=linewidths)\n",
    "                            axes[1, j].scatter(X_embedded_imX_inherit[:, 0], X_embedded_imX_inherit_L2[:, 1], c=plot_metric_df.iloc[:, j], s=scatter_marker_size, linewidths=linewidths)\n",
    "                            axes[2, j].scatter(embedding_imX_inherit_L2[:, 0], embedding_imX_inherit_L2[:, 1], c=plot_metric_df.iloc[:, j], s=scatter_marker_size, linewidths=linewidths)\n",
    "                            axes[3, j].scatter(data_phate_imX_inherit_L2[:, 0], data_phate_imX_inherit_L2[:, 1], c=plot_metric_df.iloc[:, j], s=scatter_marker_size, linewidths=linewidths)\n",
    "                        elif j in [12, 13]: # gt_imX_reinit_L2 ngt_imX_reinit_L2\n",
    "                            axes[0, j].scatter(X_r_imX_reinit_L2[:, 0], X_r_imX_reinit_L2[:, 1], c=plot_metric_df.iloc[:, j], s=scatter_marker_size, linewidths=linewidths)\n",
    "                            axes[1, j].scatter(X_embedded_imX_reinit_L2[:, 0], X_embedded_imX_reinit_L2[:, 1], c=plot_metric_df.iloc[:, j], s=scatter_marker_size, linewidths=linewidths)\n",
    "                            axes[2, j].scatter(embedding_imX_reinit_L2[:, 0], embedding_imX_reinit_L2[:, 1], c=plot_metric_df.iloc[:, j], s=scatter_marker_size, linewidths=linewidths)\n",
    "                            axes[3, j].scatter(data_phate_imX_reinit_L2[:, 0], data_phate_imX_reinit_L2[:, 1], c=plot_metric_df.iloc[:, j], s=scatter_marker_size, linewidths=linewidths)\n",
    "\n",
    "                        # for the top-most row\n",
    "                        axes[0, j].set_xlabel(plot_metric_df.columns[j])\n",
    "                        axes[0, j].xaxis.set_label_position('top')\n",
    "                        # for the left-most column\n",
    "                        if j == 0:\n",
    "                            for i in range(len(plot_kinds)):\n",
    "                                axes[i, j].set_ylabel(plot_kinds[i])\n",
    "                        # for all subplots\n",
    "                        for i in range(len(plot_kinds)):\n",
    "                            axes[i, j].set_xticks([])\n",
    "                            axes[i, j].set_yticks([])\n",
    "#                     fig.suptitle('%s best %s %s' % (dataset_dir, plot_metric, output_dir))\n",
    "                    fig.suptitle('%s %s' % (dataset_dir, plot_metric))\n",
    "                    #fig.tight_layout()\n",
    "#                     plt.subplot_tool()\n",
    "    #                 fig.supxlabel(\"clustering method\") # require matplotlib 3.4\n",
    "    #                 fig.supylabel(\"plotting method\") # require matplotlib 3.4\n",
    "    #                 raise\n",
    "\n",
    "print(\"Finish!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['gt', 'gt_unscaled', 'gt_normalized', 'gt_imX_unscaled_inherit',\n",
       "       'ngt_imX_unscaled_inherit', '0.2-400-inherit', 'gt_imX_unscaled_reinit',\n",
       "       'ngt_imX_unscaled_reinit', '0.2-400-reinit',\n",
       "       'gt_imX_unscaled_inherit_L2', 'ngt_imX_unscaled_inherit_L2',\n",
       "       '0.2-400-inherit-L2', 'gt_imX_unscaled_reinit_L2',\n",
       "       'ngt_imX_unscaled_reinit_L2', '0.2-400-reinit-L2', 'RaceID3', 'SC3',\n",
       "       'Monocle2', 'SIMLR', 'DRjCC'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plot_metric_df.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'mouse_embryos'"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "504"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cluster)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6., 4.])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig.get_size_inches()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.0"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "fig.dpi"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig.get_size_inches() * fig.dpi"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:plot]",
   "language": "python",
   "name": "conda-env-plot-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
